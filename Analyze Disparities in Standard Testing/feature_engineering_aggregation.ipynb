{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be858436",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ece0a95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"E:\\Group Folder\\Data\\cleaned_data_backup.csv\", low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b9f62cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Left over cleaning\n",
    "df.columns = df.columns.str.lower()\n",
    "df['exam_subject'] = df['exam_subject'].str.lower()\n",
    "df = df[df['exam_subject'] != 'civics']\n",
    "\n",
    "# Removing cases when the state is null\n",
    "df = df[df['t_state'].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d388eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the number of ged_ready tests a candidate gave\n",
    "num_ged_ready_tests = {}\n",
    "for group_index, sub_df in df[[\"candidate_id\",\"ged_ready\",\"exam_subject\"]].groupby([\"candidate_id\",\"exam_subject\"]):\n",
    "    num_ged_ready_tests[group_index] = sub_df[\"ged_ready\"].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dad0c7b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtering out practice tests\n",
    "df = df[df['ged_ready'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eb10b359",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replacing score with nan if its not in the valid range\n",
    "df.loc[df[\"score\"]<100,\"score\"] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e88541b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flags indicating pass/failure\n",
    "flag_cols = ['first_passed', 'first_complete', 'make_passed', 'make_complete']\n",
    "df.loc[df[\"score\"].isnull(), flag_cols] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eab2477f",
   "metadata": {},
   "source": [
    "### Feature Engineering\n",
    "Following features are created at the test level before aggregation:\n",
    "- Based on Cadidate's Test Performance/Behaviour\n",
    "    - `no_show`: If the exam score is 0, candidate did not show up to the exam\n",
    "    - `first_try`: Candidate passed the exam in the first try\n",
    "- Based on dates: The difference is in days.\n",
    "    - `prep_time`: Difference between `account_creation_date` and `exam_date`\n",
    "    - `time_to_credential`: Difference between `account_creation_date` and `credential_date`\n",
    "    - `age`: Difference between `birth_year` and year the exam was taken in.\n",
    "- Based on location:\n",
    "    - `out_of_town`: Zip from candidate's location is different from zipcode of the test location. Matching cities is problematic as its a free text string.\n",
    "    - `out_of_state`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6b8709f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_cols = ['account_setup_complete_date','exam_start','credential_date']\n",
    "for col in date_cols:\n",
    "    df[col] = pd.to_datetime(df[col], errors=\"coerce\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "45c25a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating some date based features\n",
    "df[\"prep_time\"] = (df[\"exam_start\"]-df[\"account_setup_complete_date\"]).dt.days\n",
    "df[\"time_to_credential\"] = (df[\"credential_date\"]-df[\"account_setup_complete_date\"]).dt.days\n",
    "df[\"age\"] = df[\"exam_start\"].dt.year-df[\"birth_year\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f41c89d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating some features (at test level) based on location\n",
    "df[\"out_of_town\"] = df[\"zip\"] != df[\"zipcode\"] # zip is candidate's location, zipcode is from the test location\n",
    "df[\"out_of_state\"] = df[\"c_state\"] != df[\"t_state\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8bf7f3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating features based on the test results\n",
    "df['no_show'] = df['score'] == 0\n",
    "\n",
    "# Filling in no shows with false for passing flags\n",
    "for col in flag_cols:\n",
    "    df[col] = df[col].map({\"True\":True,\"False\":False}).fillna(False)\n",
    "\n",
    "df['first_try'] = df['first_passed'] & df['first_complete']\n",
    "flag_cols.append(\"first_try\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd12abdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "continuous_colums = [\"score\"]+[\"prep_time\",\"age\"] # \"time_to_credential\", null values\n",
    "\n",
    "binary_candidate_lvl = ['study_helpful_adult_education_class',\n",
    "       'study_helpful_adult_education_teacher',\n",
    "       'study_helpful_audio_study_materials',\n",
    "       'study_helpful_books_printed_study_material', 'study_helpful_ged_ready',\n",
    "       'study_helpful_materials_mobile_app',\n",
    "       'study_helpful_online_course_video_study_materials',\n",
    "       'study_helpful_other', 'study_helpful_social_networking_website',\n",
    "       'study_helpful_tv_study_program',\n",
    "       'study_location_test_preparation_center', 'indian_or_alaskan', 'asian',\n",
    "       'african_american', 'race_decline', 'white', 'race_none',\n",
    "       'hawaiian_or_pacific']\n",
    "\n",
    "binary_test_lvl = ['on_vue','no_show'] + [\"out_of_town\", \"out_of_state\"]\n",
    "\n",
    "multi_category_columns = ['gender', 'highest_grade_completed', 'c_state', 't_state', 'juris_name', \"studied_for_ged\",\n",
    "                          'testing_reason', 'school_incomplete_reason', 'language_code','zipcode']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f44d0aa7",
   "metadata": {},
   "source": [
    "### Aggregation\n",
    "\n",
    "#### At Candidate Level\n",
    "\n",
    "Since there may be candidate level or even regional differences in the performance for each subject, we aggregate for each subject a cadidate appeared for. Depending on the type of the column we treat them differently:\n",
    "\n",
    "- __Continuous Columns__: We take the mean of the continuous columns to get the central tendency at the candidate level.\n",
    "- __Categorical Columns__:\n",
    "    - Binary Candidate Level: These columns stay constant for a particular candidate, we can take the \"first\" value.\n",
    "    - Binary Test Level: We need to sum up these values to get an aggregation of the performance of a candidate across time.\n",
    "        - Flag Columns (`flag_cols`) are a special category for this as they indicate the overall result for a candidate, thus we should take the latest result or the max result.\n",
    "    - Multi Category Columns: These are also candidate level columns, and hence we should take the mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4b3d666c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[flag_cols+binary_candidate_lvl+binary_test_lvl] = df[flag_cols+binary_candidate_lvl+binary_test_lvl].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "68cdaa4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating aggregation dictionary based on the logic discussed above\n",
    "cand_agg_dict = {}\n",
    "\n",
    "for col in continuous_colums:\n",
    "    cand_agg_dict[col] = \"mean\"\n",
    "    \n",
    "for col in flag_cols:\n",
    "    cand_agg_dict[col] = \"max\"\n",
    "    \n",
    "for col in binary_candidate_lvl:\n",
    "    cand_agg_dict[col] = \"first\"\n",
    "\n",
    "for col in binary_test_lvl:\n",
    "    cand_agg_dict[col] = sum\n",
    "\n",
    "for col in multi_category_columns:\n",
    "    cand_agg_dict[col] = lambda x: pd.Series.mode(x)[0]\n",
    "\n",
    "cand_agg_dict[\"result_id\"] = \"nunique\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5ad554b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_grouper = df.groupby([\"candidate_id\",\"exam_subject\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "322dd40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_agg = candidate_grouper.agg(cand_agg_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5f45428f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding number of practice tests from the map created earlier\n",
    "candidate_agg[\"num_practice_tests\"] = candidate_agg.index.map(num_ged_ready_tests)\n",
    "\n",
    "# Unique number of results is the number of tests taken\n",
    "candidate_agg.rename(columns={\"result_id\":\"num_tests\",\"c_state\":\"candidate_state\"},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "18724195",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prop_fill(df, prop_fill_cols=[\"gender\"],\n",
    "              values_to_replace=[\"DECLINE\",\"NONBINARY\"]):\n",
    "    \"\"\"\n",
    "    We replace the values in the columns `prop_fill_cols`.\n",
    "    The values defined in `values_to_replace` are replaced.\n",
    "    Filling in the columns with the given proportions of all values in a certain \n",
    "    column which is not in values to replace.\n",
    "    \"\"\"\n",
    "    for col in prop_fill_cols:\n",
    "        fill_index = df[df[col].isin(values_to_replace)].index\n",
    "        fill_values = list(set(df[col].unique())-set(values_to_replace))\n",
    "        fill_props = df[df[col].isin(fill_values)][col].value_counts(normalize=True)\n",
    "        fill_splits = [int(len(fill_index)*x) for x in fill_props[:-1]]\n",
    "        split_index = np.split(fill_index, fill_splits)\n",
    "        for idx, val in zip(split_index, fill_values):\n",
    "            df.loc[idx, col] = val\n",
    "        return df\n",
    "\n",
    "# Replacing the unknown gender values proportionately\n",
    "candidate_agg = prop_fill(candidate_agg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1d96b453",
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_agg = pd.get_dummies(candidate_agg, columns=[\"gender\",\"language_code\"], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "72630459",
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_agg.to_csv('E:\\Group Folder\\Data\\candidate_lvl_feats.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22a82940",
   "metadata": {},
   "source": [
    "#### At zipcode level\n",
    "Our logic changes slightly as now we need to:\n",
    "- For `flag_cols`: Calculate the mean to get the average pass rate and so on.\n",
    "- For `continuous_columns`: The mean is still appropriate, example average age of the candidate from the zip code\n",
    "- For `binary_candidate_lvl`: We take the sum to get the total counts in various categories\n",
    "- For `binary_test_lvl`: Again we take the sum to get the total counts of tests taken remotely, out of town/state etc.\n",
    "- For `multi_category_columns`: We take the mode to find the most frequent category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0057d632",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating aggregation dictionary based on the logic discussed above\n",
    "zip_agg_dict = {}\n",
    "\n",
    "for col in continuous_colums+[\"distances\"]:\n",
    "    zip_agg_dict[col] = \"mean\"\n",
    "    \n",
    "for col in flag_cols:\n",
    "    zip_agg_dict[col] = \"mean\"\n",
    "\n",
    "## Adding candidate level aggregate columns\n",
    "for col in binary_candidate_lvl+[\"num_tests\",\"num_practice_tests\"]:\n",
    "    zip_agg_dict[col] = sum\n",
    "\n",
    "# Removing zipcode and categorical columns for which we have dummy variables now \n",
    "multi_category_columns = list(set(multi_category_columns) - {\"gender\",\"language_code\",\"zipcode\",\"zip\",\"c_state\"})\n",
    "\n",
    "for col in multi_category_columns:\n",
    "    zip_agg_dict[col] = lambda x: pd.Series.mode(x)[0]\n",
    "\n",
    "# adding new dummy variables (which need to be summed up for each zip)\n",
    "binary_test_lvl+= ['gender_MALE','language_code_ESP']\n",
    "for col in binary_test_lvl:\n",
    "    zip_agg_dict[col] = sum\n",
    "    \n",
    "# we want to count the number of candidates\n",
    "zip_agg_dict[\"candidate_id\"] = \"nunique\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e1d7265",
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_agg = pd.read_csv('E:\\Group Folder\\Data\\candidate_lvl_feats.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bb2bba93",
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_agg = candidate_agg.reset_index().groupby([\"zipcode\",\"exam_subject\"]).agg(zip_agg_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3de6e3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding number of test centers\n",
    "zip_agg[\"num_test_centers\"] = df[[\"zipcode\",\"exam_subject\",\"test_center_id\"]].groupby([\"zipcode\",\"exam_subject\"]).agg('nunique')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "887a8387",
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_agg.rename(columns={\"candidate_id\":\"num_candidates\"},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f9299550",
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_agg.to_csv('E:\\Group Folder\\Data\\zipcode_lvl_feats.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec124d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
